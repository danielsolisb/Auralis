auralis-subscriber — Servicio MQTT → MySQL (Django)
Objetivo

Servicio independiente (no acoplado a Django/Celery) que:
Descubre sensores activos y sus topics MQTT desde la BD.
Se suscribe por sensor (sin duplicar suscripciones).
Guarda mediciones en measurements_measurement con hora local del servidor.
Evalúa políticas de alerta (AlertPolicy) y crea events (events_alarm / events_warning).
Corre como systemd service en Ubuntu.

Arquitectura (resumen)

1 cliente MQTT (Paho) maneja N topics.
3 hilos principales:
sync_loop: cada X segundos sincroniza sensores/políticas y (des)subscripciones.
writer_loop: inserta mediciones en lotes.
event_writer_loop: inserta eventos (alarms/warnings).
BD: MySQL via PyMySQL.
Config por /etc/default/auralis-subscriber.
Nota: actualmente la hora guardada es local del servidor (datetime.now()), como se acordó.

Requisitos

Ubuntu 20.04+ con Python 3.8+ (ideal 3.10+).
Acceso a MySQL (host/puerto/credenciales válidas).
Broker MQTT (ej. Mosquitto) accesible (TCP 1883 recomendado).
Paquetes: python3-venv, pip, y permisos sudo.

Arbol de archivos

/opt/auralis-subscriber/
├── requirements.txt
├── config.py
├── db.py
├── models.py
├── evaluator.py
├── mqtt_worker.py
└── run.py

/etc/default/auralis-subscriber        # variables de entorno (env)
/etc/systemd/system/auralis-subscriber.service

Instalación paso a paso

1) Usuario y carpeta del servicio
sudo mkdir -p /opt/auralis-subscriber
sudo adduser --system --group --home /opt/auralis-subscriber auralis
sudo chown -R auralis:auralis /opt/auralis-subscriber
sudo chmod 750 /opt/auralis-subscriber

2) (Recomendado) Script Bash que deja todo listo
Crea y ejecuta este script; reescribe los .py, crea venv e instala requirements:

sudo nano /root/auralis_fix.sh

archivo:
______________________________________________________________________________________
#!/usr/bin/env bash
set -euo pipefail

BASE="/opt/auralis-subscriber"
mkdir -p "$BASE"

echo "[1/5] Reescribiendo archivos del servicio…"

cat > "$BASE/requirements.txt" << "EOF"
paho-mqtt>=1.6.1
PyMySQL>=1.1.0
python-dotenv>=1.0.1
tzlocal>=5.2
EOF

cat > "$BASE/config.py" << "EOF"
import os
from dataclasses import dataclass

def getenv(name: str, default=None, cast=None):
    val = os.getenv(name, default)
    if cast and val is not None:
        try:
            return cast(val)
        except Exception:
            return default
    return val

@dataclass
class Settings:
    # Database
    DB_NAME: str = getenv("DB_NAME", "Auralis")
    DB_USER: str = getenv("DB_USER", "root")
    DB_PASSWORD: str = getenv("DB_PASSWORD", "")
    DB_HOST: str = getenv("DB_HOST", "127.0.0.1")
    DB_PORT: int = getenv("DB_PORT", 3306, int)

    # MQTT
    MQTT_HOST: str = getenv("MQTT_HOST", "127.0.0.1")
    MQTT_PORT: int = getenv("MQTT_PORT", 1883, int)
    MQTT_USERNAME: str = getenv("MQTT_USERNAME", None)
    MQTT_PASSWORD: str = getenv("MQTT_PASSWORD", None)
    MQTT_TLS: bool = getenv("MQTT_TLS", "false").lower() in ("1","true","yes","on")
    MQTT_KEEPALIVE: int = getenv("MQTT_KEEPALIVE", 60, int)
    MQTT_CLIENT_ID: str = getenv("MQTT_CLIENT_ID", None)
    MQTT_QOS: int = getenv("MQTT_QOS", 0, int)

    # Subscriber behaviour
    SYNC_INTERVAL_SEC: int = getenv("SYNC_INTERVAL_SEC", 15, int)
    WRITE_BATCH_SIZE: int = getenv("WRITE_BATCH_SIZE", 200, int)
    WRITE_FLUSH_MS: int = getenv("WRITE_FLUSH_MS", 800, int)
    MAX_QUEUE: int = getenv("MAX_QUEUE", 5000, int)
    LOG_LEVEL: str = getenv("LOG_LEVEL", "INFO")
    TZ_NAME: str = getenv("TZ_NAME", "America/Guayaquil")

    # Event evaluation
    EVAL_PERSISTENCE_DEFAULT: int = getenv("EVAL_PERSISTENCE_DEFAULT", 0, int)
    EVAL_USE_HYSTERESIS: bool = getenv("EVAL_USE_HYSTERESIS", "true").lower() in ("1","true","yes","on")

    # Optional dedupe
    ENABLE_DEDUP: bool = getenv("ENABLE_DEDUP", "false").lower() in ("1","true","yes","on")
    DEDUP_MIN_MS: int = getenv("DEDUP_MIN_MS", 50, int)
EOF

cat > "$BASE/db.py" << "EOF"
import pymysql
import threading
from typing import Iterable, Optional, Tuple

class DB:
    def __init__(self, host, port, user, password, dbname):
        self._conn_params = dict(
            host=host, port=port, user=user, password=password,
            database=dbname, autocommit=False,
            cursorclass=pymysql.cursors.DictCursor, charset="utf8mb4"
        )
        self._lock = threading.Lock()
        self._conn = None

    def connect(self):
        with self._lock:
            if self._conn is None:
                self._conn = pymysql.connect(**self._conn_params)
            else:
                try:
                    self._conn.ping(reconnect=True)
                except Exception:
                    self._conn = pymysql.connect(**self._conn_params)

    def executemany(self, sql: str, rows: Iterable[Tuple]):
        self.connect()
        with self._conn.cursor() as cur:
            cur.executemany(sql, rows)
        self._conn.commit()

    def execute(self, sql: str, params: Optional[Tuple]=None):
        self.connect()
        with self._conn.cursor() as cur:
            cur.execute(sql, params)
            res = cur.fetchall()
        self._conn.commit()
        return res
EOF

cat > "$BASE/models.py" << "EOF"
from typing import List, Optional, Tuple
from dataclasses import dataclass
from db import DB

@dataclass
class SensorRow:
    id: int
    station_id: int
    company_id: int
    sensor_type_id: int
    name: str
    mqtt_topic: Optional[str]
    is_active: bool
    min_value: Optional[float]
    max_value: Optional[float]

@dataclass
class PolicyRow:
    id: int
    scope: str         # GLOBAL, COMPANY, SENSOR_TYPE, STATION, SENSOR
    alert_mode: str    # ABS or REL
    company_id: Optional[int]
    sensor_type_id: Optional[int]
    station_id: Optional[int]
    sensor_id: Optional[int]
    warn_high: Optional[float]
    alert_high: Optional[float]
    enable_low_thresholds: bool
    warn_low: Optional[float]
    alert_low: Optional[float]
    hysteresis: Optional[float]
    persistence_seconds: Optional[int]
    bands_active: bool
    color_warn: Optional[str]
    color_alert: Optional[str]
    updated_at: str

class Repo:
    def __init__(self, db: DB):
        self.db = db

    def list_active_sensors(self) -> List[SensorRow]:
        sql = '''
            SELECT s.id, s.station_id, st.company_id, s.sensor_type_id, s.name,
                   s.mqtt_topic, s.is_active, s.min_value, s.max_value
            FROM sensorhub_sensor AS s
            JOIN sensorhub_station AS st ON s.station_id = st.id
            WHERE s.is_active = 1 AND s.mqtt_topic IS NOT NULL AND s.mqtt_topic <> ''
        '''
        rows = self.db.execute(sql)
        return [
            SensorRow(
                id=r["id"], station_id=r["station_id"], company_id=r["company_id"],
                sensor_type_id=r["sensor_type_id"], name=r["name"],
                mqtt_topic=r["mqtt_topic"], is_active=bool(r["is_active"]),
                min_value=r["min_value"], max_value=r["max_value"]
            )
            for r in rows
        ]

    def list_active_policies(self) -> List[PolicyRow]:
        sql = '''
            SELECT id, scope, alert_mode, company_id, sensor_type_id, station_id, sensor_id,
                   warn_high, alert_high, enable_low_thresholds, warn_low, alert_low,
                   hysteresis, persistence_seconds, bands_active, color_warn, color_alert, updated_at
            FROM sensorhub_alertpolicy
            WHERE bands_active = 1
            ORDER BY updated_at DESC
        '''
        rows = self.db.execute(sql)
        return [
            PolicyRow(
                id=r["id"], scope=r["scope"], alert_mode=r["alert_mode"],
                company_id=r["company_id"], sensor_type_id=r["sensor_type_id"],
                station_id=r["station_id"], sensor_id=r["sensor_id"],
                warn_high=r["warn_high"], alert_high=r["alert_high"],
                enable_low_thresholds=bool(r["enable_low_thresholds"]),
                warn_low=r["warn_low"], alert_low=r["alert_low"],
                hysteresis=r["hysteresis"], persistence_seconds=r["persistence_seconds"],
                bands_active=bool(r["bands_active"]),
                color_warn=r["color_warn"], color_alert=r["color_alert"],
                updated_at=str(r["updated_at"])
            )
            for r in rows
        ]

    def insert_measurements(self, rows: List[Tuple[int, str, float]]):
        if not rows: return
        sql = "INSERT INTO measurements_measurement (sensor_id, measured_at, value) VALUES (%s, %s, %s)"
        self.db.executemany(sql, rows)

    def create_alarm(self, sensor_id: int, iso_ts: str, value: float, severity: str, description: str, notified=False):
        sql = '''INSERT INTO events_alarm
                 (sensor_id, timestamp, value, description, is_active, severity, notified)
                 VALUES (%s,%s,%s,%s,1,%s,%s)'''
        self.db.execute(sql, (sensor_id, iso_ts, value, description, severity, 1 if notified else 0))

    def create_warning(self, sensor_id: int, iso_ts: str, value: float, description: str):
        sql = '''INSERT INTO events_warning
                 (sensor_id, timestamp, value, description, is_active)
                 VALUES (%s,%s,%s,%s,1)'''
        self.db.execute(sql, (sensor_id, iso_ts, value, description))
EOF

cat > "$BASE/evaluator.py" << "EOF"
from typing import Dict, Optional
from dataclasses import dataclass
from datetime import datetime
from models import PolicyRow, SensorRow

@dataclass
class Thresholds:
    warn_low: Optional[float] = None
    alert_low: Optional[float] = None
    warn_high: Optional[float] = None
    alert_high: Optional[float] = None
    hysteresis: Optional[float] = None
    enable_low: bool = False

SCOPE_ORDER = ["GLOBAL", "COMPANY", "SENSOR_TYPE", "STATION", "SENSOR"]

def _conv(policy: PolicyRow, v: Optional[float], smin: float, smax: float) -> Optional[float]:
    if v is None: return None
    if policy.alert_mode == "ABS": return float(v)
    span = max(0.0, float(smax) - float(smin))
    return float(smin) + float(v) * span

def build_thresholds_for_sensor(policies_by_scope: Dict[str, list], sensor: SensorRow) -> Thresholds:
    smin = float(sensor.min_value or 0.0)
    smax = float(sensor.max_value or 1.0)
    th = Thresholds(enable_low=False)
    for scope in SCOPE_ORDER:
        for p in policies_by_scope.get(scope, []):
            if scope == "COMPANY" and p.company_id != sensor.company_id: continue
            if scope == "SENSOR_TYPE" and p.sensor_type_id != sensor.sensor_type_id: continue
            if scope == "STATION" and p.station_id != sensor.station_id: continue
            if scope == "SENSOR" and p.sensor_id != sensor.id: continue
            if p.warn_high is not None: th.warn_high = _conv(p, p.warn_high, smin, smax)
            if p.alert_high is not None: th.alert_high = _conv(p, p.alert_high, smin, smax)
            if p.hysteresis is not None: th.hysteresis = _conv(p, p.hysteresis, smin, smax)
            if p.enable_low_thresholds:
                th.enable_low = True
                if p.warn_low is not None: th.warn_low = _conv(p, p.warn_low, smin, smax)
                if p.alert_low is not None: th.alert_low = _conv(p, p.alert_low, smin, smax)
    return th

class StateTracker:
    def __init__(self, persistence_default: int = 0, use_hysteresis: bool = True):
        self.state: Dict[int, str] = {}
        self.since: Dict[int, datetime] = {}
        self.persistence_default = persistence_default
        self.use_hysteresis = use_hysteresis

    def classify(self, sensor: SensorRow, th: Thresholds, value: float, now: datetime, persistence_seconds: Optional[int]) -> Optional[str]:
        hys = th.hysteresis or 0.0 if self.use_hysteresis else 0.0
        band = "NORMAL"
        if th.alert_high is not None and value >= th.alert_high + hys:
            band = "ALERT_HIGH"
        elif th.warn_high is not None and value >= th.warn_high + hys:
            band = "WARN_HIGH"
        elif th.enable_low:
            if th.alert_low is not None and value <= th.alert_low - hys:
                band = "ALERT_LOW"
            elif th.warn_low is not None and value <= th.warn_low - hys:
                band = "WARN_LOW"

        prev = self.state.get(sensor.id, "NORMAL")
        if band == prev:
            self.since.pop(sensor.id, None)
            return band

        if band != "NORMAL":
            since = self.since.get(sensor.id)
            if not since:
                self.since[sensor.id] = now
                return None
            wait = persistence_seconds if persistence_seconds is not None else self.persistence_default
            if wait and (now - since).total_seconds() < wait:
                return None

        self.state[sensor.id] = band
        self.since.pop(sensor.id, None)
        return band
EOF

cat > "$BASE/mqtt_worker.py" << "EOF"
import time, threading, queue, logging, random, socket
from typing import Dict, Tuple, List
from datetime import datetime
import paho.mqtt.client as mqtt

from config import Settings
from db import DB
from models import Repo, SensorRow, PolicyRow
from evaluator import build_thresholds_for_sensor, StateTracker

def local_iso(dt: datetime) -> str:
    return dt.strftime("%Y-%m-%d %H:%M:%S")

class SubscriberService:
    def __init__(self, settings: Settings):
        self.s = settings
        self.db = DB(self.s.DB_HOST, self.s.DB_PORT, self.s.DB_USER, self.s.DB_PASSWORD, self.s.DB_NAME)
        self.repo = Repo(self.db)

        self.topic_to_sensor: Dict[str, SensorRow] = {}
        self.subscribed_topics: set[str] = set()
        self.policies: List[PolicyRow] = []

        self.measure_q: "queue.Queue[Tuple[int,str,float]]" = queue.Queue(maxsize=self.s.MAX_QUEUE)
        self.event_q: "queue.Queue[Tuple[str,int,str,float,str]]" = queue.Queue(maxsize=2000)

        self.tracker = StateTracker(persistence_default=self.s.EVAL_PERSISTENCE_DEFAULT, use_hysteresis=self.s.EVAL_USE_HYSTERESIS)
        self.last_value_by_sensor: Dict[int, Tuple[float, float]] = {}

        self.client = None
        self.stop_event = threading.Event()

    def _build_client(self):
        client_id = self.s.MQTT_CLIENT_ID or f"auralis-sub-{socket.gethostname()}-{random.randint(1000,9999)}"
        c = mqtt.Client(client_id=client_id, clean_session=True)
        if self.s.MQTT_TLS:
            c.tls_set()
        if self.s.MQTT_USERNAME:
            c.username_pw_set(self.s.MQTT_USERNAME, self.s.MQTT_PASSWORD or None)
        c.on_connect = self.on_connect
        c.on_message = self.on_message
        c.on_disconnect = self.on_disconnect
        return c

    def start(self):
        logging.info("Starting SubscriberService")
        self.client = self._build_client()
        self.client.connect_async(self.s.MQTT_HOST, self.s.MQTT_PORT, keepalive=self.s.MQTT_KEEPALIVE)
        self.client.loop_start()

        threading.Thread(target=self.writer_loop, name="writer", daemon=True).start()
        threading.Thread(target=self.event_writer_loop, name="event-writer", daemon=True).start()
        threading.Thread(target=self.sync_loop, name="sync", daemon=True).start()

    def stop(self):
        self.stop_event.set()
        if self.client:
            try:
                self.client.loop_stop()
                self.client.disconnect()
            except Exception:
                pass

    def sync_loop(self):
        while not self.stop_event.is_set():
            try:
                sensors = self.repo.list_active_sensors()
                self._refresh_topics(sensors)
                self.policies = self.repo.list_active_policies()
            except Exception as e:
                logging.exception("sync_loop error: %s", e)
            self.stop_event.wait(self.s.SYNC_INTERVAL_SEC)

    def _refresh_topics(self, sensors: List[SensorRow]):
        new_map = {s.mqtt_topic: s for s in sensors if s.mqtt_topic}
        for topic, srow in new_map.items():
            if topic not in self.subscribed_topics and self.client:
                logging.info("Subscribe %s -> sensor %s(#%d)", topic, srow.name, srow.id)
                self.client.subscribe(topic, qos=self.s.MQTT_QOS)
                self.subscribed_topics.add(topic)
        for topic in list(self.subscribed_topics):
            if topic not in new_map and self.client:
                logging.info("Unsubscribe %s", topic)
                self.client.unsubscribe(topic)
                self.subscribed_topics.remove(topic)
                self.topic_to_sensor.pop(topic, None)
        self.topic_to_sensor = new_map

    def on_connect(self, client, userdata, flags, rc):
        if rc == 0:
            logging.info("Connected to MQTT broker")
            for topic in self.topic_to_sensor.keys():
                client.subscribe(topic, qos=self.s.MQTT_QOS)
                self.subscribed_topics.add(topic)
        else:
            logging.error("MQTT connect failed rc=%s", rc)

    def on_disconnect(self, client, userdata, rc):
        logging.warning("MQTT disconnected rc=%s", rc)

    def on_message(self, client, userdata, msg):
        topic = msg.topic
        srow = self.topic_to_sensor.get(topic)
        if not srow:
            return
        payload = None
        try:
            payload = msg.payload.decode("utf-8").strip()
            value = float(payload)
        except Exception:
            logging.warning("Non-numeric payload on %s: %r", topic, payload)
            return

        now = datetime.now()
        iso_ts = local_iso(now)

        try:
            self.measure_q.put_nowait((srow.id, iso_ts, value))
        except queue.Full:
            try:
                _ = self.measure_q.get_nowait()
                self.measure_q.put_nowait((srow.id, iso_ts, value))
            except Exception:
                logging.error("measure_q overflow; dropping sample")

        try:
            by_scope = {}
            for p in self.policies:
                by_scope.setdefault(p.scope, []).append(p)
            th = build_thresholds_for_sensor(by_scope, srow)

            persistence = None
            for scope in ("SENSOR","STATION","SENSOR_TYPE","COMPANY","GLOBAL"):
                for p in by_scope.get(scope, []):
                    if (scope=="SENSOR" and p.sensor_id==srow.id) or \
                       (scope=="STATION" and p.station_id==srow.station_id) or \
                       (scope=="SENSOR_TYPE" and p.sensor_type_id==srow.sensor_type_id) or \
                       (scope=="COMPANY" and p.company_id==srow.company_id) or \
                       (scope=="GLOBAL"):
                        if p.persistence_seconds is not None:
                            persistence = p.persistence_seconds
                            break
                if persistence is not None:
                    break

            band = self.tracker.classify(srow, th, value, now, persistence)
            if band and band != "NORMAL":
                if band.startswith("ALERT"):
                    desc = f"Fuera de rango: {band.replace('_',' ').title()} (v={value:.3f})"
                    self.event_q.put_nowait(("ALARM", srow.id, iso_ts, value, desc))
                else:
                    desc = f"Advertencia: {band.replace('_',' ').title()} (v={value:.3f})"
                    self.event_q.put_nowait(("WARNING", srow.id, iso_ts, value, desc))
        except Exception as e:
            logging.exception("Error evaluating policy for topic %s: %s", topic, e)

    def writer_loop(self):
        buf: List[Tuple[int,str,float]] = []
        last_flush = time.time()
        while not self.stop_event.is_set():
            try:
                item = self.measure_q.get(timeout=0.2)
                buf.append(item)
            except queue.Empty:
                pass
            now = time.time()
            if buf and (len(buf) >= self.s.WRITE_BATCH_SIZE or (now - last_flush) * 1000.0 >= self.s.WRITE_FLUSH_MS):
                try:
                    self.repo.insert_measurements(buf)
                    logging.debug("Inserted %d measurements", len(buf))
                except Exception as e:
                    logging.exception("insert_measurements failed: %s", e)
                finally:
                    buf.clear()
                    last_flush = now

    def event_writer_loop(self):
        while not self.stop_event.is_set():
            try:
                kind, sensor_id, iso_ts, value, desc = self.event_q.get(timeout=0.5)
            except queue.Empty:
                continue
            try:
                if kind == "ALARM":
                    severity = "ALTA"
                    self.repo.create_alarm(sensor_id, iso_ts, value, severity, desc, notified=False)
                else:
                    self.repo.create_warning(sensor_id, iso_ts, value, desc)
            except Exception as e:
                logging.exception("Insert event failed: %s", e)
EOF

cat > "$BASE/run.py" << "EOF"
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import signal, logging, time
from config import Settings
from mqtt_worker import SubscriberService

def setup_logging(level: str):
    logging.basicConfig(
        level=getattr(logging, level.upper(), logging.INFO),
        format="%(asctime)s | %(levelname)s | %(threadName)s | %(message)s"
    )

def main():
    s = Settings()
    setup_logging(s.LOG_LEVEL)
    logging.info("Auralis Subscriber starting…")
    logging.info("DB=%s@%s:%s MQTT=%s:%s TLS=%s", s.DB_NAME, s.DB_HOST, s.DB_PORT, s.MQTT_HOST, s.MQTT_PORT, s.MQTT_TLS)

    srv = SubscriberService(s)

    def _sigterm(signum, frame):
        logging.warning("Signal %s received, stopping…", signum)
        srv.stop()
        raise SystemExit(0)  # salir del loop principal rápido

    signal.signal(signal.SIGTERM, _sigterm)
    signal.signal(signal.SIGINT, _sigterm)

    srv.start()
    try:
        while True:
            time.sleep(2)
    finally:
        srv.stop()
        logging.info("Auralis Subscriber stopped.")

if __name__ == "__main__":
    main()
EOF

echo "[2/5] Ajustando permisos…"
chown -R auralis:auralis "$BASE"
chmod +x "$BASE/run.py"

echo "[3/5] Creando venv si no existe…"
if [ ! -d "$BASE/.venv" ]; then
  sudo -u auralis python3 -m venv "$BASE/.venv"
fi

echo "[4/5] Instalando/actualizando dependencias…"
sudo -u auralis "$BASE/.venv/bin/pip" install --upgrade pip setuptools wheel
sudo -u auralis "$BASE/.venv/bin/pip" install -r "$BASE/requirements.txt"

echo "[5/5] Listo. Archivos limpios y dependencias instaladas."
echo "Siguiente paso: crea /etc/default/auralis-subscriber y el unit de systemd."

______________________________________________________________________________________
Guarda (Ctrl+O, Enter) y sal (Ctrl+X).
Ejecuta:

sudo chmod +x /root/auralis_fix.sh
sudo /root/auralis_fix.sh


3) Variables de entorno

sudo nano /etc/default/auralis-subscriber

Contenido (ajusta lo necesario):

# ==== Database ====
DB_NAME=Auralis
DB_USER=root
DB_PASSWORD=daniel586
DB_HOST=34.30.17.212
DB_PORT=3306

# ==== MQTT ====
MQTT_HOST=34.30.17.212
MQTT_PORT=1883
MQTT_TLS=false
MQTT_KEEPALIVE=60
MQTT_QOS=0

# ==== Behaviour ====
SYNC_INTERVAL_SEC=10
WRITE_BATCH_SIZE=200
WRITE_FLUSH_MS=800
MAX_QUEUE=5000
LOG_LEVEL=INFO
TZ_NAME=America/Guayaquil

# ==== Events ====
EVAL_PERSISTENCE_DEFAULT=0
EVAL_USE_HYSTERESIS=true

# ==== Optional dedupe ====
ENABLE_DEDUP=false
DEDUP_MIN_MS=50

4) systemd unit
sudo nano /etc/systemd/system/auralis-subscriber.service

Contenido:
[Unit]
Description=Auralis MQTT Subscriber
After=network.target

[Service]
Type=simple
EnvironmentFile=/etc/default/auralis-subscriber
User=auralis
Group=auralis
WorkingDirectory=/opt/auralis-subscriber
ExecStart=/opt/auralis-subscriber/.venv/bin/python /opt/auralis-subscriber/run.py
Restart=always
RestartSec=3
NoNewPrivileges=true
PrivateTmp=true
ProtectSystem=full
ProtectHome=true

[Install]
WantedBy=multi-user.target

5) Habilitar y arrancar
sudo systemctl daemon-reload
sudo systemctl enable auralis-subscriber
sudo systemctl start auralis-subscriber
sudo journalctl -u auralis-subscriber -f

Operación

Ver estado:
systemctl status auralis-subscriber --no-pager -l

Logs en vivo:
journalctl -u auralis-subscriber -f

Reiniciar:
sudo systemctl restart auralis-subscriber

Detener:
sudo systemctl stop auralis-subscriber

El run.py ya incluye salida rápida con SystemExit(0) al recibir SIGTERM/SIGINT para evitar “colgados”.

Variables de entorno (explicación rápida)

DB_*: conexión MySQL.
MQTT_*: host/puerto/QoS del broker.
SYNC_INTERVAL_SEC: cada cuánto sincroniza sensores/policies y (des)suscribe topics.
WRITE_BATCH_SIZE / WRITE_FLUSH_MS: batch y flush mínimo para insertar mediciones.
MAX_QUEUE: tamaño máximo de cola de mediciones.
LOG_LEVEL: DEBUG/INFO/WARNING.
TZ_NAME: zona de referencia (ahora no se usa para convertir, pero la dejamos en config).
EVAL_*: parámetros por defecto de evaluación (hysteresis/persistence).
ENABLE_DEDUP/DEDUP_MIN_MS: filtro opcional para ignorar valores idénticos en ventanas muy cortas.

Tablas esperadas (nombres)

sensorhub_sensor, sensorhub_station, sensorhub_alertpolicy
measurements_measurement
events_alarm, events_warning
Si cambian los nombres en tu proyecto, hay que ajustar los SELECT/INSERT en models.py.

Índices recomendados

measurements_measurement(sensor_id, measured_at) (ya lo tienes).
(Opcional anti-duplicado duro):

ALTER TABLE measurements_measurement
ADD UNIQUE INDEX uniq_sensor_ts (sensor_id, measured_at);
y si usas esto, cambiar a INSERT IGNORE o ON DUPLICATE KEY UPDATE según tu preferencia.


Troubleshooting
“Packet sequence number wrong - got X expected Y”

Causa: varias consultas desde hilos distintos usando la misma conexión PyMySQL (no thread-safe).
Estado actual: nuestra clase DB comparte una conexión entre hilos → puede generar este error bajo carga.
Plan de mejora (próximo cambio):

Pasar a conexión por hilo (thread-local) o a un pool pequeño (2–4 conns: sync, writer(s), events).
Como test rápido, se puede serializar temporalmente execute/executemany con un lock global (reduce throughput, pero confirma el diagnóstico).
“El servicio tarda en parar”
Ya se añadió raise SystemExit(0) en run.py para salir rápido del loop principal al recibir SIGTERM.
Si persiste, revisar:
loop_stop() de Paho y disconnect() (ya llamados).
Que los hilos no estén esperando queue.get() por demasiado tiempo (usamos timeouts cortos).

Ver hora del servidor / MySQL
date "+%Y-%m-%d %H:%M:%S %Z %z"
timedatectl
mysql -h <host> -u <user> -p -e "SELECT NOW() AS mysql_now, @@global.time_zone, @@session.time_zone;"

Si quieres alinear:
sudo timedatectl set-timezone America/Guayaquil

Cómo actualizar código
Edita los .py en /opt/auralis-subscriber/.
(Opcional) reinstala deps si cambió requirements.txt.
Reinicia el servicio:
sudo systemctl restart auralis-subscriber
